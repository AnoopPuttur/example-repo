Day 1 -------------------------------------------------------------------
kubectl create -f example1.yaml
 kubectl get pods
 kubectl get po
 kubectl get po -o wide
 kubectl describ pod tomcat-pod
 kubectl describe pod tomcat-pod

12  kubectl create -f example1.yaml
   13  kubectl get po 
   14  kubectl get po -o wide 
   15  ping 192.168.1.4
   16  kubectl exec -it tomcat-pod -- /bin/sh
   17  kubectl delete pod tomcat-pod 
   18  kubectl get po 
   19  history
   
 
   
    4  cat > example2.yaml
    5  kubectl create -f example2.yaml
    6  kubectl get po 
    7  kubectl get po -o wide
    8  kubectl get po -l app=tomcat-app
    9  kubectl describe rc tomcat-rc 
   10  kubectl scale rc tomcat-rc --replicas=7
   11  kubectl get po -o wide
   12  kubectl scale rc tomcat-rc --replicas=2
   13  kubectl get po -o wide
   14  kubectl scale rc tomcat-rc --replicas=4
   15  kubectl get po -o wide
   16  kubectl delete pod tomcat-rc-5bhp7 
   17  kubectl get po -o wide
   18  kubectl delete rc tomcat-rc 
   19  kubectl get po -l app=tomcat-app
   20  kubectl create -f example2.yaml
   21  kubectl get po -l app=tomcat-app
   22  kubetl delete -f example2.yaml
   23  kubectl delete -f example2.yaml



26  kubectl get po
   27  kubectl run tomcat-pod1 --image=vishymails/tomcatimage:1.0 --labels=app=tomcat-app --dry-run=client
   28  kubectl run tomcat-pod1 --image=vishymails/tomcatimage:1.0 --labels=app=tomcat-app --dry-run=client -o yaml
   29  kubectl get po
   30  kubectl run tomcat-pod1 --image=vishymails/tomcatimage:1.0 --labels=app=tomcat-app
   31  kubectl get po
   32  kubectl run tomcat-pod2 --image=vishymails/tomcatimage:1.0 --labels=app=tomcat-app
   33  kubectl run tomcat-pod3 --image=vishymails/tomcatimage:1.0 --labels=app=tomcat-app
   34  kubectl get po
   35  kubectl get po -o wide -l app=tomcat-app
   36  kubectl get rc 
   37  ls
   38  kubectl create -f example2.yaml
   39  kubectl get po 
   40  kubectl get rc 
   41  kubectl delete pod tomcat-pod1
   42  kubectl get rc 
   43  kubectl get po 
   44  kubectl describe rc tomcat-rc 

12 kubectl create -f example3.yaml
  13 kubectl get rs
  14 kubectl get po
  15 kubectl get po -o wide
  16 kubectl describe rs tomcat-rs
  17 kubectl scale rs tomcat-rs --replicas=6
  18 kubectl get po -o wide
  19 kubectl scale rs tomcat-rs --replicas=2
  20 kubectl get po -o wide
  21 kubectl get po -o wide
  22 kubectl delete rs tomcat-rs
  23 kubectl delete rs tomcat-pod
  24 kubectl delete pod tomcat-pod


   4  cat > example4.yaml
    5  kubectl create -f example4.yaml 
    6  kubectl get deploy 
    7  kubectl get deploy -l app=tomcat-app
    8  kubectl get po 
    9  kubectl get po -o wide 
   10  kubectl get rs 
   11  kubectl describe deploy tomcat-deploy 

Terminal1 ------------------
 14  kubectl get deploy -o wide 
   15  kubectl set image deploy tomcat-deploy tomcat-container=nginx:1.9.1
   16  kubectl set image deploy tomcat-deploy tomcat-containers=nginx:1.9.1
   17  kubectl rollout status deployment/tomcat-deploy 
   18  kubectl get deploy -o wide 
   19  kubectl set image deploy tomcat-deploy tomcat-containers=nginx:1.91 --record
   20  kubectl get deploy -o wide 
   21  kubectl rollout status deployment/tomcat-deploy 
   22  kubectl get deploy -o wide 
   23  kubectl rollout status deployment/tomcat-deploy 
   24  kubectl scale deployment tomcat-deploy --replicas=7
   25  kubectl get deploy -o wide 
   26  kubectl scale deployment tomcat-deploy --replicas=3
   27  kubectl get deploy -o wide 
Terminal 2----------------------------------------
3  kubectl rollout history deployment/tomcat-deploy
    4  kubectl rollout undo deployment/tomcat-deploy


Day2 ----------------------------------
    
    
    Create Alias for kubectl  command:
 alias g=kubectl
Q 01) #Create a new pod called admin-pod with image busybox. Allow it to be able to set system_time. Container should sleep for 3200 seconds.


 4  alias g=kubectl 
    5  g run admin-pod --image=busybox --command sleep 3200 --dry-run=client -o yaml 
  

Create a new deployment called web-proj-268 with image nginx:1.16 and one replica. Next, upgrade the deployment to version 1.17 using rolling update. 
Make sure that the version upgrade is recorded in the resource annotation.


alias g=kubectl
  6  g create deployment web-proj-268 --image=nginx:1.16
    7  g describe deployment web-proj-268
    8  g get deploy
    9  g get po 
   10  g get rs
   11  g set image deployment web-proj-268 nginx=nginx:1.7 --record 
   12  g rollout history deployment web-proj-268



Create a new deployment web-003, scale this deployment to 3 replicas, make sure desired number of pods are always running.

  14  g create deployment web-003 --image=nginx --replicas=3
   15  g get po 


 deploy a web-load-5461 pod using nginx:1.17 with the label set to tier=web
 
 kubectl run tomcat-pod1 --image=nginx:1.17 --labels=tier=web --dry-run=
 
 
 
 
 Create a new deployment called nginx-deployment with an image nginx:1.16 and 5 replicas. There are 2 worker nodes in our cluster. 
#Please make sure no pod will get deployed on node7.
 
 
 
 
 Create static pod on node07 called static-nginx with image nginx and you have to make sure that it is recreated/restarted automatically in case of any failure happens.

5  ps -ef | grep kubelet
    6  sudo grep static /var/lib/kubelet/config.yaml
    7  ls /etc/kubernetes/manifests
    8  alias g=kubectl
    9  g run static-nginx --image=nginx --dry-run=client -o yaml 
   10  g run static-nginx --image=nginx --dry-run=client -o yaml > example9.yaml
   11  g get nodes 
   12  cat example9.yaml | ssh node01 "tee example9.yaml"
   13  clead
   14  clear
   15  g get po 
   16  g get po -o wide 
   17  g delete pod static-nginx-node01
   18  g get po -o wide 
   19  history
   
   
   
   WORKER NODE
   
   4  ps -ef | grep kubelet
    5  sudo grep static /var/lib/kubelet/config.yaml
    6  sudo cp example9.yaml /etc/kubernetes/config.yaml
    7  sudo cp example9.yaml /etc/kubernetes/manifests/.
    8  ls /etc/kubernetes/manifests


services -
     4  cat > example9.yaml
    5  cat > example10.yaml
    6  kubectl create -f example9.yaml
    7  kubectl create -f example10.yaml
    8  kubectl get po 
    9  kubectl get svc 
   10  kubectl describe svc my-service
   11  curl http://192.168.1.4:8080
   12  curl http://192.168.1.5:8080
   13  curl http://192.168.1.6:8080
   14  kubectl describe svc my-service
   15  kubectl get po -o wide
   16  kubectl get node -o wide
   17  curl http://172.30.2.2:8080
   18  curl http://172.30.2.2:31000
   19  history


   Expose "audit-web-app" pod to by creating a service "audit-web-app-service" on port 30002 on nodes of given cluster.


 alias g=kubectl
    5  g run audit-web-app --image=nginx --port=8080
    6  g expose pod audit-web-app --name=audit-web-app-svc --type=NodePort --dry-run=client -o yaml | tee example12.yaml
    7  kubectl get po 
    8  g apply -f example12.yaml
    9  g get pods -o wide 
   10  g describe audit-web-app-svc
   11  g get svc
   12  g describe svc audit-web-app-svc
   
   
   
   
   Create a replicaset (name : web-replica, image=nginx, replicas=3), there is already a pod running in our cluster.  
 Please make sure that total count of pods running in the cluster is not more than 3.
  
  
  
  
  Volumes - 
  
   cat > example13.yaml
   15  kubectl create -f example13.yaml
   16  kubectl exec -it tomcat-pod -- /bin/sh
   17  kubectl get po 
   18  kubectl delete po tomcat-pod
   19  kubectl get po 
   20  kubectl create -f example13.yaml
   21  kubectl exec -it tomcat-pod -- /bin/sh

MultiContainer
9  cat > example16.yaml
   10  kubectl create -f example16.yaml
   11  kubectl get po -o wide
   12  kubectl exec -it multicontainer-pod -- /bin/sh
   13  kubectl exec --container=producer -it multicontainer-pod -- /bin/sh
   14  history

PV/PVC
7  clear
    8  kubectl create -f example19.yaml
    9  kubectl get pv 
   10  kubectl create -f example20.yaml
   11  kubectl get pvc
   12  kubectl get pv 
   13  history


19  kubectl delete pvc kube-pv
   20  kubectl delete pv kube-pv
   21  kubectl create -f example19.yaml
   22  cat > example21.yaml
   23  kubectl create -f example21.yaml
   24  kubectl get pv 
   25  kubectl get pvc
   26  kubectl delete pvc my-disk-claim
   27  kubectl create -f example20.yaml
   28  kubectl get pv 
   29  kubectl get pvc
   30  cat > example22.yaml
   31  kubectl create -f example22.yaml
   32  kubectl get po -o wide 
   33  kubectl exec -it pv-pod -- /bin/bash
   34  history




   
   
   
   
   Create a pod called pod-multi with 2 containers as it is descripted below:
   Container 1 : name:container1, image: nginx 
   Container 2 : name:container2, image: busybox, command: sleep 4800
   
   
   
   
   Create a persistent volume with given specifications:
  Volume Name - pv-rnd
  storage - 100Mi
  Access modes - ReadWriteMany
  host path - /pv/host-data-rnd
 
 
 
 
 Craete a PersistentVolume, PersistentVolumeClaim and Pod with below specifications

  PV - name : mypvl , Size: 100Mi, AccessModes: ReadWritemany, Hostpath: /pv/log, Reclaim Policy: Retain
  PVC - name:  pv-claim-l, Storage request: 50Mi, Access Modes: ReadWritemany 
  Pod - name : my-nginx-pod, image Name: nginx, Volume: PersistentVolumeClaim: pv-claim-l, volume mount : /log



Secrets -----
 4  echo -n 'admin' | base64 > username.txt
    5  echo -n 'password123' | base64 > password.txt
    6  kubectl get secrets 
    8  cat username.txt
    0  cat password.txt
   11  kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt
   12  kubectl get secrets 
   13  kubectl describe secrets db-user-pass
   
   
   
 Config map
management.endpoints.enabled-by-default=true 
management.endpoint.info.enabled=true 
management.security.enabled=false 
management.endpoints.web.exposure.include=*







server.port= 9000
server.servlet.context-path=/oracle 
oracleprops.greeting= Thank you and visit again - altered 
oracleprops.greeting1= New Data




4  cat > application1.properties
    5  cat > application2.properties
    6  kubectl create configmap myconfig-map --from-literal=key1=value1 --from-literal=key2=value2
    7  kubectl create configmap myconfig-map1 --from-file=./application1.properties --from-file=./application2.properties
    8  kubectl get cm

    
     4  cat > example1.yaml
    5  cat > example16.yaml
    6  kubectl create -f example1.yaml
    7  kubectl create -f example16.yaml
    8  kubectl get po 
    9  kubectl logs tomcat-pod
   10  kubectl logs multicontainer-pod -c consumer
   11  kubectl logs multicontainer-pod -c producer
   12  kubectl logs tomcat-pod
   13  clear
   14  kubectl logs --tail=20 tomcat-pod
   15  kubectl logs --tail=20 --timestampstomcat-pod
   16  kubectl logs --tail=20 --timestamps tomcat-pod
   17  kubectl logs multicontainer-pod -c consumer
   18  kubectl logs --timestamps multicontainer-pod -c consumer
   19  history 
   
   
   
   21  cat > example39.yaml
   22  kubectl get ns 
   23  kubectl create -f example39.yaml 
   24  kubectl get ns 
   25  kubectl get po 
   26  kubectl get po -n default 
   27  kubectl get po -n my-ns1
   28  ls
   29  kubectl create -f example1.yaml 
   30  cat > example40.yaml
   31  kubectl create -f example40.yaml 
   32  kubectl get po -n my-ns2
   33  kubectl get po --all-namespaces
   
   
   
   
   
   4  cat > example1.yaml
    5  cat > example16.yaml
    6  cat > example40.yaml
    7  kubectl get ns
    8  kubectl create namespace cka
    9  kubectl get ns
   10  kubectl create -f example1.yaml
   11  kubectl create -f example16.yaml
   12  kubectl create namespace my-ns2
   13  kubectl create -f example40.yaml
   14  kubectl run nginx --image=nginx --namespace=cka
   15  kubectl get po 
   16  kubectl get po --namespace=my-ns2
   17  kubectl get po --namespace=cka
   18  kubectl get po
   19  kubectl config set-context --current --namespace=cka
   20  kubectl get po 
   21  kubectl create -f example1.yaml
   22  kubectl get po 
   23  kubectl api-resources
   24  kubectl api-resources --namespaced=false
   25  kubectl api-resources --namespaced=true
   26  kubectl api-resources --namespaced=true -o wide 
   27  history
   
   
   
   
    4  cat > example42.yaml
    5  kubectl get po -o wide 
    6  kubectl describe pod init-container-demo
    7  kubectl create -f example42.yaml 
    8  kubectl get po -o wide 
    9  kubectl describe pod init-container-demo
   10  kubectl logs init-container-demo -c init-container-ubuntu
   11  kubectl logs init-container-demo -c init-container-busybox
   12  kubectl logs init-container-demo -c init-container-nginx
   
   
   
   
   Create a pod called delta-pod in defence namespace belonging to the development environment (env=dev)  and frontend tier (tier=front), image: nginx:1.17
  
  
  
  
  A new application finance-audit-pod is deployed in finance namespace. Find out what is wrong with it and fix the issue. 
 NOTE: No configuration changes allowed, you can only delete or recreate the pod.
  Below command will create a scenario for us:
   g create ns finance  ; g run  finance-audit-pod --image=busybox -n finance --command sleeo 180
   
   
   
   
   A pod “prod-pod” (image=nginx, port 8080) in default namespace is not running. We need fix it and bring it in running state.
 
 
 
 
 
 mount secret in 2 pods using filesystem and environment variable
 
 
 
 
 Create a user “nec-adm". Grant nec-adm access to cluster, should have permissions to create, list, get, update, and delete pods in nec namespace 
 Private key exist in location:  /vagrant/nec-adm.key and csr at /vagrant/nec-adm.csr
 
 
 
 
 
 
  5  alias g=kubectl 
    6  g create ns nec 
    7  openssl genrsa -out nec-adm.key 2048
    8  ls
    9  openssl req -new -key nec-adm.key -out nec-adm.csr
   10  ls
   11  history
   
   
   
   
   12  cat nec-adm.csr | base64 | tr -d "\n"
   13  cat > example45.yaml
   14  kubectl create -f example45.yaml
   15  cat > example45.yaml
   16  kubectl create -f example45.yaml
   17  cat > example45.yaml
   18  kubectl create -f example45.yaml
   19  g get csr
   20  g certificate approve nec-adm
   21  g get csr
   22  cat > example46.yaml
   23  kubectl create -f example46.yaml
   24  cat > example47.yaml
   25  kubectl create -f example47.yaml
   26  g get rolebinding.rbac.authorization.k8s.io -n nec 
   27  g get pods -n nec --as nec-adm
   28  g auth can-i get pods -n default --as nec-adm
   29  g auth can-i get pods -n nec --as nec-adm
   30  g auth can-i get list -n nec --as nec-adm
   31  g auth can-i  list pods -n nec --as nec-adm
   32  g api-resources --all-namespaces
   33  g api-resources --namespaced=true -o wide  
   34  kubectl get role
   35  kubectl get role -n nec-adm
   36  kubectl get roles -n nec
   
   
   
   
   ETCD DB BACKUP 


backup.sh
---------

ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save /root/etcd-backup.db







  alias g=kubectl
   20  g get pods -A | grep etcd
   21  g describe pod etcd-controlplane -n kube-system | grep -A20 -i command
   22  cat > backup.sh
   23  sudo bash ./backup.sh
   24  ls /root
   25  history



:use JSONPath query to retrieve our OS images of all K8s nodes and store it in a file ~/allNodeOSImages8.txt


kubectl get nodes -o jsonpath='{.items[*].status.nodeInfo.osImage}' | tee allNodeOSImage8.txt


All ingress Pod-to-Pod communication has been denied across all namespaces. 
You want to allow the Pod busybox in namespace k1 to communicate with Pod nginx in namespace k2. 
You'll create a network policy to achieve that.


STEPS TO SOLVE

Create the objects from the YAML manifest setup.yaml.
Inspect the objects in the namespace k1 and k2.
Determine the virtual IP address of Pod nginx in namespace k2. Try to make a wget call on port 80 from the Pod busybox in namespace k1 to the Pod nginx in namespace k2. The call will fail with the current setup.
Create a network policy that allows performing ingress calls for all Pods in namespace k1 to the Pod nginx in namespace k2. Pods in all other namespaces should be denied to make ingress calls to Pods in namespace k2.
Repeat step 3 to verify that a network connection can be established.



apiVersion: v1
kind: Namespace
metadata:
  name: k1
  labels:
    role: consumer
---
apiVersion: v1
kind: Namespace
metadata:
  name: k2
  labels:
    role: producer
---
kind: Pod
apiVersion: v1
metadata:
  name: busybox
  namespace: k1
  labels:
    app: frontend
spec:
  containers:
  - name: busybox
    image: busybox:1.36.1
    command: ["sh", "-c", "sleep 1h"]
---
kind: Pod
apiVersion: v1
metadata:
  name: nginx
  namespace: k2
  labels:
    app: backend
spec:
  containers:
  - name: nginx
    image: nginx:1.23.4-alpine
    ports:
    - containerPort: 80
      protocol: TCP







apiVersion : networking.k8s.io/v1
kind : NetworkPolicy
metadata :
  name : default-deny-ingress
  namespace : k2
spec :
  podSelector : {}
  policyTypes :
    - Ingress





apiVersion : networking.k8s.io/v1
kind : NetworkPolicy
metadata :
  name : allow-ingress-networkpolicy
  namespace : k2
spec :
  podSelector : 
    matchLabels :
      app : backend
  policyTypes :
    - Ingress
  ingress :
    - from :
        - namespaceSelector :
            matchLabels :
              role : consumer
      ports :
        - protocol : TCP
          port : 80

          








4  cat > example51.yaml
    5  cat > example52.yaml
    6  cat > example53.yaml
    7  kubectl create -f example51.yaml
    8  kubectl create -f example52.yaml
    9  kubectl get pod -n k1
   10  kubectl get pod -n k1 -o wide 
   11  kubectl get pod -n k2 -o wide 
   12  kubectl exec -it busybox -n k1 -- wget --timeout=5 192.168.1.5:80
   13  kubectl create -f example53.yaml
   14  kubectl exec -it busybox -n k1 -- wget --timeout=5 192.168.1.5:80
   15  history
